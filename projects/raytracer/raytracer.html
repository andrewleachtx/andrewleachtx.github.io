<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>Portfolio</title>
    <meta name="description" content="" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" href="../../style.css" />
    <link rel="stylesheet" href="../../mediaqueries.css" />

    <!-- MathJax -->
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>

    <!-- For Pretty Code -->
    <link rel="stylesheet" href="../../prism.css" />
    <script src="../../prism.js"></script>
  </head>

  <body>
    <html>
      <nav id="desktop-nav">
        <div class="logo">Andrew D. Leach</div>

        <div>
          <ul class="nav-links">
            <li>
              <a href="../../">
                <img
                  src="../../assets/icon-home.svg"
                  alt="home icon"
                  class="icon-grow"
                />
              </a>
            </li>
            <li><a href="../../#about">me</a></li>
            <li><a href="../../#experience">experience</a></li>
            <li><a href="../../#contact">contact</a></li>
            <li><a href="../../pages/projects.html">projects</a></li>
            <li><a href="../../pages/fun.html">fun</a></li>
          </ul>
        </div>
      </nav>

      <nav id="hamburger-nav">
        <div class="logo">Andrew D. Leach</div>
        <div class="hamburger-menu">
          <div class="hamburger-icon" onclick="toggleMenu()">
            <span></span>
            <span></span>
            <span></span>
          </div>
          <div class="menu-links">
            <li><a href="../../#about" onclick="toggleMenu()">about</a></li>
            <li>
              <a href="../../#experience" onclick="toggleMenu()">experience</a>
            </li>
            <li><a href="../../#contact">contact</a></li>
            <li>
              <a href="../../pages/projects.html" onclick="toggleMenu()"
                >projects</a
              >
            </li>
            <li>
              <a href="../../pages/fun.html" onclick="toggleMenu()">fun</a>
            </li>
          </div>
        </div>
      </nav>

      <div class="project-sidebar">
        <a href="#raytracer">Ray Tracing</a>
        <a href="#rasterization">Rasterization</a>
        <a href="#what-is-raytracing">Ray Tracing In 3 Steps</a>
        <a href="#c++-implementation">C++ Implementation</a>
        <a href="#scenes">Scene Images</a>
        <a href="#threading">Threading & Optimizations</a>
        <a href="#bounding-volumes">Bounding Volume Problem</a>
        <a href="#anti-aliasing">Anti-Aliasing</a>
      </div>

      <section id="raytracer" class="project">
        <h3 class="project-title">Ray Tracing</h3>

        <p>
          Growing up playing video games and fantasizing about one day building
          my dream computer with only the most outrageously powerful parts, the
          phrase
          <a
            href="https://en.wikipedia.org/wiki/Ray_tracing_(graphics)"
            target="_blank"
            >ray tracing</a
          >
          was simple: it could make games look <em>real</em> - like you were
          were looking through a window, not a screen. (It also meant really,
          really expensive).
        </p>

        <p>
          After my introduction to graphics, the way I would now describe ray
          tracing to my friends is as follows:
          <strong>you already know how to ray trace</strong>. That is to say, it
          is the intuitive way to render a scene; ray tracing replicates what
          our eyes and brains do
          <a
            href="https://www.sighthound.com/blog/human-eye-fps-vs-ai-why-ai-is-better"
            target="_blank"
            >60 times every second</a
          >.
        </p>

        <div class="project-img-container">
          <img src="./assets/scene.png" alt="My Scene" class="project-img" />
          <div>Scene 9</div>
        </div>

        <p>
          I am sure there are many nuances to my explanation of ray tracing.
          This serves as a blog and documentation for my logic and
          implementation in C++ for a ray tracer. Because this was done in my
          graphics course (with the guidance of
          <a href="https://people.engr.tamu.edu/sueda/index.html"
            >Dr. Shinjiro Sueda</a
          >), the codebase is not public.
        </p>

        <h2 id="rasterization">Rasterization</h2>
        <p>
          Before starting, I should note that ray tracing is not a new concept -
          despite recent popularity in the gaming industry over the past decade,
          it has been around since the 1960s. Why is it popular now? Well, I
          think you'll be able to come up with an answer yourself.
        </p>
        <p>
          There must then be other methods responsible for the feats of
          real-time graphics over the past ~30 years. The most well-known
          strategy in the conversation, adjacent to ray tracing, is
          <a
            href="https://blogs.nvidia.com/blog/whats-difference-between-ray-tracing-rasterization/#attachment_39178"
            target="_blank"
            >rasterization</a
          >. If a <strong>raster</strong> is a group of pixels in a 2D grid,
          then <strong>rasterization</strong> is the process by which we convert
          3D shapes into pixels on your (2D) screen.
        </p>
        <p>
          There is a lot of rasterization lore that is tempting to dive into,
          but lets assume you've already read up on it (hopefully soon I can
          write up docs for my
          <a href="../../pages/projects.html">rasterizer project</a>).
        </p>

        <h2 id="what-is-raytracing">Ray Tracing In 3 Steps</h2>
        <div class="project-img-container">
          <img
            class="project-img"
            src="./assets/frustum.png"
            alt="Screenshot from Michael Stewart"
            style="width: 100%; height: 400px"
          />
          <div>
            Screenshot taken from Michael Stewart's amazing ray tracing
            <a
              href="https://michaelstewart2.github.io/RayTeaching1.1/index.html"
              target="_blank"
              >visualizer</a
            >
          </div>
        </div>

        <p>
          Imagine your eyes shoot <em>infinitely</em> many rays out to every
          possible object in the world around you. The watermelon slices on your
          counter, your floor, your tortoise, etc. Well, when one of those rays
          reaches or <strong>intercepts</strong> with the watermelon, you see
          green and red (unless you collect rare watermelons).
        </p>

        <p>
          Well imagine that watermelon, like any other object, is composed of
          tiny spots of color that combine to make the pattern you recognize as
          a watermelon. Each ray your eye shoots
          <strong>hits a unique spot</strong>, and bounces to any nearby light
          sources to ascertain how "bright" that green spot should be. That is
          what happens for one pixel in ray tracing.
        </p>

        <p>
          Now, ray tracing says that in front of your eyes there is a 2D grid,
          known as the
          <a
            href="https://help.agi.com/STKComponents/html/GraphicsCameraViewFrustum.htm"
            target="_blank"
            >view frustum</a
          >. In our case, this view frustum is composed of evenly distributed
          pixels. Sounds familiar? That's because you're reading this off of
          one.
        </p>

        <p>
          Now, we <strong>always</strong> have a scene in front of us. Maybe a
          tortoise, some trees, a house, whatever. We want to transform that 3D
          scene into pixels on a screen. Now the question is,
          <strong
            >what colors do we give to each pixel so that when combined on the
            screen, they tell our brain there is a tortoise?</strong
          >
        </p>

        <pre><code class="language-python">for pixel in image:
            1. generate ray
            2. find closest object that intersects with ray
            3. compute color of pixel based on light(s)</code></pre>

        $$\vec{x}(t) = \vec{p} + t\hat{v}$$

        <p>
          A ray has an origin \(\vec{p}\), and a direction \(\hat{v}\). At a
          high level ray tracing argues that if for each pixel you shoot a ray
          from the eye (camera) through the pixel's center, you will
          <em>eventually</em> hit an object in the scene. At that intersection
          point, you can determine the intensity of light with a typical
          <a
            href="https://en.wikipedia.org/wiki/Blinn%E2%80%93Phong_reflection_model"
            target="_blank"
            >Blinn Phong</a
          >
          model.
        </p>

        <p>
          Basically, you get the color of the object at that point, and the
          degree to which that color is accentuated depends on the light
          sources.
          <strong>The pixel receives that final color.</strong>
        </p>

        <div class="project-img-container">
          <img
            class="project-img"
            src="assets/tracingbasics.png"
            alt="Tracing Basic PNG"
            style="width: 50%; height: auto"
          />
          <div>
            Ray trace diagram,
            <a
              href="https://en.wikipedia.org/wiki/Ray_tracing_(graphics)#/media/File:Ray_trace_diagram.svg"
              target="_blank"
              >Wikipedia</a
            >
          </div>
        </div>

        <p>
          For example, this sphere became an orange ball on the frustum because
          a collection of rays from the camera intersected with the sphere at
          those orange points. The other rays hit perhaps white planes (the
          ground and walls) and became white, or gray (shadows) for ones that
          were occluded from the light's perspective.
        </p>

        <h2 id="c++-implementation">C++ Implementation</h2>
        <p>
          I wrote this ray tracer in vanilla C++17, primarily relying on STL
          libraries. The only supplementary libraries I used are:
        </p>

        <ul>
          <li>
            <a href="https://github.com/g-truc/glm" target="_blank">glm</a> to
            abstract matrix math
          </li>
          <li>
            <a
              href="https://github.com/nothings/stb/blob/master/stb_image_write.h"
              target="_blank"
              >stb_image_write.h</a
            >
            to export pixel data into an image
          </li>
          <li>
            <a
              href="https://github.com/tinyobjloader/tinyobjloader"
              target="_blank"
              >tinyobjloader</a
            >
            to load any .obj meshes (such as the bunny in scenes 6-7)
          </li>
          <li>
            <a
              href="https://fileadmin.cs.lth.se/cs/Personal/Tomas_Akenine-Moller/raytri/"
              target="_blank"
            >
              raytri.c</a
            >
            for optimized ray-triangle intersection tests within meshes
          </li>
        </ul>

        <p>
          Setting theory aside, actually implementing the ray tracer required a
          lot of object-oriented design and refactoring of code. Most
          abstractions consisted of one or more glm::vec3's, namely ones that
          held (x, y, z) information. To name some classes I ended up with:
        </p>

        <ul>
          <li>
            <strong>Ray</strong> to store XYZ values for a ray's origin and
            direction
          </li>
          <li>
            <strong>Light</strong> to define position and intensity for light
            sources
          </li>
          <li>
            <strong>Camera</strong> for storing eye position + translations,
            aspect ratio, fovy, etc
          </li>
          <li>
            <strong>Material</strong> to store the unique diffuse and specular
            colors/floats a specific object should have
          </li>
          <li>
            <strong>Shape</strong> with polymorphism / inheritance as the
            primary goal for multiple shape types and their unique intersection
            and hit methods
          </li>
          <li>
            <strong>Scene</strong> as a wrapper container for specific instances
            of lights and shapes
          </li>
          <li>
            <strong>Mesh</strong> to store vectorized information about OBJ data
          </li>
        </ul>

        <h2 id="scenes">Scenes</h2>
        <p>
          These scenes can be rendered at variable resolution (within reason);
          anti-aliasing samples per pixel; and parallel multithreaded chunk
          counts. Rendering was done on the CPU as my existing code does not
          leverage parallelization through CUDA or any other GPU frameworks.
        </p>

        <p>
          This did not serve to be problematic given the simplicity of the
          scenes and efficiency of the code (especially with std::thread on the
          CPU).
        </p>

        <p>
          You may note some scenes are listed in pairs - this is because certain
          scenes were designed incrementally; the latter is presented. Scenes
          1-8 were rendered in 512x512 without anti-aliasing on. Scene 9,
          however, was rendered in 1024x1024 with 8x AA sampling per pixel.
        </p>

        <div class="project-img-group">
          <div class="project-img-list">
            <img
              src="./assets/scene1.png"
              alt="Scene 1"
              class="project-img-scene"
            />
            Scene 1 (no shadows) and 2 (shadows)
          </div>

          <div class="project-img-list">
            <img
              src="./assets/scene3.png"
              alt="Scene 3"
              class="project-img-scene"
            />
            Scene 3 (ellipsoid)
          </div>

          <div class="project-img-list">
            <img
              src="./assets/scene4.png"
              alt="Scene 4"
              class="project-img-scene"
            />
            Scene 4 (singular reflection) and 5 (recursive reflection)
          </div>

          <div class="project-img-list">
            <img
              src="./assets/scene6.png"
              alt="Scene 6"
              class="project-img-scene"
            />
            Scene 6 (triangle-ray intersection for .obj mesh)
          </div>

          <div class="project-img-list">
            <img
              src="./assets/scene7.png"
              alt="Scene 7"
              class="project-img-scene"
            />
            Scene 7 (triangle-ray intersections with model transformation)
          </div>

          <div class="project-img-list">
            <img
              src="./assets/scene8.png"
              alt="Scene 8"
              class="project-img-scene"
            />
            Scene 8 (camera transformation of Scene 1)
          </div>

          <div class="project-img-list">
            <img
              src="./assets/scene.png"
              alt="Scene 9"
              class="project-img-scene"
            />
            Scene 9 (anti-aliasing, reflective blinn-phong, constructive solid
            geometry, multithreading, and boxes).
          </div>
        </div>

        <h2 id="threading">Multithreading & Render Optimization</h2>
        <p>
          The ray tracing algorithm performs a lot of work in series: iterate
          over all pixels, send rays that may even recursively spawn more rays,
          etc... It is a very <strong>computationally expensive</strong>
          process, especially for high resolution images where \(rays \times
          width \times height\) grows rapidly.
        </p>

        <p>
          Yet, this work for one pixel is independent of another; concurrency is
          not a problem, and this nature lends ray tracing to parallelization.
          With some simple changes, I was able to leverage
          <a
            href="https://en.cppreference.com/w/cpp/thread/thread"
            target="_blank"
            >std::thread</a
          >
          to split up the processing for groups of pixels into
          <strong>chunks</strong>, and join them at the end.
        </p>

        <p>
          The following data was collected at 1024x1024, 1 ray per pixel (no
          AA), and 30 max recursive bounces for reflections. The series
          generation is based on 1 thread (normal), and for parallel 16 threads.
        </p>

        <table class="performance-table">
          <thead>
            <tr>
              <th>Scene</th>
              <th>Resolution</th>
              <th>Series Runtime (seconds)</th>
              <th>Parallel Runtime (seconds)</th>
              <th>Improvement (%)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>1</td>
              <td>1024x1024</td>
              <td>0.367059</td>
              <td>0.149398</td>
              <td>59.30%</td>
            </tr>
            <tr>
              <td>2</td>
              <td>1024x1024</td>
              <td>0.362205</td>
              <td>0.166128</td>
              <td>54.13%</td>
            </tr>
            <tr>
              <td>3</td>
              <td>1024x1024</td>
              <td>0.629310</td>
              <td>0.227803</td>
              <td>63.80%</td>
            </tr>
            <tr>
              <td>4</td>
              <td>1024x1024</td>
              <td>3.479643</td>
              <td>0.314233</td>
              <td>90.97%</td>
            </tr>
            <tr>
              <td>5</td>
              <td>1024x1024</td>
              <td>0.975385</td>
              <td>0.302306</td>
              <td>69.01%</td>
            </tr>
            <tr>
              <td>6</td>
              <td>1024x1024</td>
              <td>50.655735</td>
              <td>9.789422</td>
              <td>80.68%</td>
            </tr>
            <tr>
              <td>7</td>
              <td>1024x1024</td>
              <td>139.551437</td>
              <td>23.142061</td>
              <td>83.42%</td>
            </tr>
            <tr>
              <td>8</td>
              <td>1024x1024</td>
              <td>0.414549</td>
              <td>0.198096</td>
              <td>52.21%</td>
            </tr>
            <tr>
              <td>9</td>
              <td>1024x1024</td>
              <td>106.289078</td>
              <td>26.270395</td>
              <td>75.29%</td>
            </tr>
          </tbody>
        </table>

        <p>
          Adding a timer with
          <a href="https://en.cppreference.com/w/cpp/chrono" target="_blank"
            >std::chrono</a
          >
          early on was one of the cooler parts of working on this project.
          <strong>However, it was more than premature optimization</strong>;
          without introducing parallelization, I would not have been able to
          rapidly develop and render these scenes in time with my other
          coursework and responsibilities. Really nice to see prior knowledge
          from system courses (and at the time, Operating Systems) come into
          play.
        </p>

        <h2 id="bounding-volumes">Bounding Volumes</h2>
        <p>
          Comparatively speaking, scenes 6, 7, and 9 are clear outliers in
          render time. This is because the use of a mesh (the
          <a href="https://en.wikipedia.org/wiki/Stanford_bunny" target="_blank"
            >Stanford bunny</a
          > for these scenes), which is actually a
          <strong>collection of very many triangles</strong>. This "shape" is
          completely different from other shapes, which were overloaded with an
          intersection function called once for that shape.
        </p>

        <p>
          For a "mesh" shape, to determine if a ray intersects with the shape,
          you must check if it intersected with any of the triangles residing
          within the mesh. Problematically,
          <strong
            >we must always perform a linear search, iterating over every single
            triangle</strong
          >.
        </p>
        <p>
          Given that the bunny has 4968 triangles, and we have \(1024^2\) pixels
          or rays, we have to do \(1024^2 * 4968\) checks in the best case (no
          reflections).
          <strong>One check per ray, for every single triangle</strong>. This
          brings up the minimum bounding box problem, which is a different beast
          entirely.
        </p>

        <div class="project-img-container">
          <img
            src="./assets/boundingboxes.png"
            alt="Bounding Volume"
            class="project-img"
            style="width: 65%; height: auto"
          />
          Bounding volumes and tradeoffs, Ericson - Real-Time Collision
          Detection
        </div>

        <p>
          The main idea behind bounding volumes is to encapsulate a complex
          shape with a simpler one, which requires much less computation in the
          intersection test.
          <strong
            >If a ray doesn't even hit the bounding volume, then you certainly
            won't intersect with the mesh</strong
          >, so no need to perform the costly loop.
        </p>

        <p>
          Using a simple bounding sphere was sufficient for bringing down render
          time exponentially, but it is not the most efficient. Because I didn't
          research and implement a more advanced bounding volume technique,
          (i.e.
          <a href="https://en.wikipedia.org/wiki/Bounding_volume_hierarchy"
            >BVH</a
          >), the bunny was a limiting factor in render time for those scenes.
        </p>

        <h2 id="anti-aliasing">Anti-Aliasing</h2>
        <p>
          Throughout this writing I have mentioned the idea of shooting a ray
          through a pixel or through
          <strong>the "center" of the pixel</strong>. This is what normal ray
          tracing without anti-aliasing does.
        </p>
        <p>
          Anti-aliasing is described as the process of
          <strong>removing jagged edges along a shape's border</strong> that
          exist because we discretely map each pixel to one color from the
          scene. This does a poor job at handling differentiating the last pixel of a
          watermelon from the blue wall behind it.
        </p>

        <div class="project-img-container">
          <img
            src="./assets/1xAA.png"
            alt="Anti-Aliasing 1x"
            class="project-img"
            style="width: 120%; height: auto"
          />
          Scene 4, no anti-aliasing (1x)
        </div>

        <p>
          Instead, what if we argued the color for a pixel should be 
          <strong
            >the weighted average of multiple rays that pass through
            the pixel?</strong
          >
          This is the fundamental idea behind this anti-aliasing - sampling
          a pixel with multiple rays to get a
          <strong>more accurate representation of its color</strong>.
        </p>

        <div class="project-img-container">
          <img
            src="./assets/mergedAA.jpg"
            alt="Anti-Aliasing 1x and 16x"
            class="project-img"
            style="width: 125%; height: auto"
          />
          <div>
            Scene 4, 512x512, no anti-aliasing (<strong>left</strong>) and 16x
            anti-aliasing (<strong>right</strong>)
          </div>
        </div>

        <p>
          As far as where you should shoot the now increased rays within a pixel, I
          chose to do it evenly throughout the pixel, but you can actually also do it
          completely randomly - the results are surprisingly good...
        </p>

        <h2>Constructive Solid Geometry</h2>
        <p>...tbd</p>
        <h2>Future</h2>
        <p>...tbd</p>
        <h2>Credits</h2>
        <p>...tbd</p>
      </section>

      <footer>
        <nav>
          <div class="nav-links-container">
            <ul class="nav-links">
              <li>
                <a href="../../">
                  <img
                    src="../../assets/icon-home.svg"
                    alt="home icon"
                    class="icon-grow"
                  />
                </a>
              </li>
              <li><a href="../../#about">me</a></li>
              <li><a href="../../#experience">experience</a></li>
              <li><a href="../../#contact">contact</a></li>
              <li><a href="../../pages/projects.html">projects</a></li>
              <li><a href="../../pages/fun.html">fun</a></li>
            </ul>
          </div>
        </nav>
        <p>&#169; 2024 Andrew Leach. All Rights Reserved.</p>
      </footer>

      <script src="../../script.js" async defer></script>
    </html>
  </body>
</html>
